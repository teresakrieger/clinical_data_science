{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Day_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "4TxxL9UEaqO9"
      },
      "source": [
        "# **Clinical Data Science and Machine Learning with Python**\n",
        " \n",
        "## **Day 2**\n",
        "\n",
        "- **Instructor**: Teresa Krieger, BIH/Charité (teresa.krieger@charite.de)\n",
        "- **Course date**: November 2021\n",
        "\n",
        "**Content**:\n",
        "\n",
        "1.   References\n",
        "2.   Library imports and data download\n",
        "3.   Data preparation\n",
        "4.   Model building\n",
        "5.   Model training\n",
        "6.   Model evaluation\n",
        "7.   Model prediction\n",
        "8.   Optional: More MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB4ROcAPaqPB"
      },
      "source": [
        "---\n",
        "## **1. References**\n",
        "\n",
        "In this course, we will use Python 3.6 (default in Colab as of February 2021).\n",
        "The following documentation and links might be useful to you:\n",
        "\n",
        "- Deep Learning:\n",
        "  - https://www.deeplearningbook.org/\n",
        "- Tensorflow and Keras:\n",
        "  - https://www.tensorflow.org/tutorials/\n",
        "  - https://keras.io/guides/\n",
        "- Source of the pneumonia X-ray dataset:\n",
        "  - https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\n",
        "\n",
        "You can also take a look at [this](https://www.youtube.com/playlist?list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF) machine learning series on Youtube, where you can learn more about e.g. bias and variance, regand some common machine learning algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5Seipdq1Owq"
      },
      "source": [
        "---\n",
        "## **2. Library imports and data download**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzGW_2hDCS1e"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.preprocessing import image\n",
        "from google.colab import files\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN9ygNZMx-W-"
      },
      "source": [
        "In this session, we will be working with chest X-ray images from patients with and without pneumonia. This data is available on Kaggle. Before we can download it, we need to set up a connection to Kaggle in our colab environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b8xdW9Jz7ST"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!wget -O kaggle.json https://www.dropbox.com/s/ewjoj1ge5u130m9/kaggle.json?dl=0\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3dhn08u0_5X"
      },
      "source": [
        "Now we can download the data from Kaggle:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQvWxd7kyAvS"
      },
      "source": [
        "!kaggle datasets download paultimothymooney/chest-xray-pneumonia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nnj3SfF1HSl"
      },
      "source": [
        "The dataset is organised into 3 folders (train, test, val) and contains subfolders for each image category (PNEUMONIA/NORMAL). There are 5,863 X-Ray images (JPEG) across the two categories. We still need to unzip the compressed data and store the folder names:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pQ8h2_DyQY1"
      },
      "source": [
        "with zipfile.ZipFile('chest-xray-pneumonia.zip', mode='r') as zf:   # Here, mode = 'r' means we are reading the zip file\n",
        "  zf.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaXHfIvT3_Ku"
      },
      "source": [
        "img_dir = os.path.join(os.getcwd(), 'chest_xray')\n",
        "test_img_dir = os.path.join(img_dir, 'test')\n",
        "train_img_dir = os.path.join(img_dir, 'train')\n",
        "val_img_dir = os.path.join(img_dir, 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn7MGAvG47JO"
      },
      "source": [
        "---\n",
        "## **3. Data preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kxcFyD649mJ"
      },
      "source": [
        "To prepare the images for processing, we will use the `ImageDataGenerator` function from `Keras`. This function automatically generates batches of image data for training and testing our model. Moreover, it can perform real-time data augmentation, for example by introducing random rotations and vertical or horizontal flips. You can find out more in the documentation [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator).\n",
        "\n",
        "For now, we will only apply the `rescale` argument to transform all images to a [0...1] grayscale range instead of [0...255] as is common for RGB images. The generator essentially reads images from the source folders in batches when they are required during training and evaluation. We will therefore set up separate instances for training, validation and testing:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBJYfeDo4qoM"
      },
      "source": [
        "train_generator = ImageDataGenerator(rescale = 1/255).flow_from_directory(\n",
        "    'chest_xray/train/',\n",
        "    target_size = (300,300),\n",
        "    batch_size = 128,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "\n",
        "val_generator = ImageDataGenerator(rescale = 1/255).flow_from_directory(\n",
        "    'chest_xray/val/',\n",
        "    target_size = (300, 300),\n",
        "    batch_size = 128,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "\n",
        "test_generator = ImageDataGenerator(rescale = 1/255).flow_from_directory(\n",
        "    'chest_xray/test/',\n",
        "    target_size = (300, 300),\n",
        "    batch_size = 128,\n",
        "    class_mode = 'binary'\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBQF0ovWU5bP"
      },
      "source": [
        "---\n",
        "## **4. Model building**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKCKbFEYrFTx"
      },
      "source": [
        "The model we are going to build consists of several components:\n",
        "\n",
        "*   **tf.keras.layers.Conv2D()**: the convolution layer which abstracts images features \n",
        "*   **tf.keras.layers.MaxPooling2D()**: a layer to reduce the information in an image while maintaining features\n",
        "*   **tf.keras.layers.Flatten()**: flattens the result into a one-dimensional array\n",
        "*   **tf.keras.layers.Dense()**: a densely connected layer\n",
        "\n",
        "We will build a five-layer convolutional neural network in which each layer consists of a Conv2D() and a MaxPooling2D() step. Then, the output of the final convolutional layer will be flattened and fit to fully connected neurons.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_6ikMm5sflP"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  \n",
        "    # Note the input shape is the size of the image (300 x 300 px) x 3 colours\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  \n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "  \n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "  \n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "  \n",
        "    # The fifth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "  \n",
        "    # Flatten output\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Densely connected hidden layer with 512 neurons\n",
        "    tf.keras.layers.Dense(512, activation='relu'), \n",
        "\n",
        "    # One output neuron with a sigmoid activation function - \n",
        "    # this will contain a value from 0 ('normal') to 1 ('pneumonia')\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmAGCFx-3E8b"
      },
      "source": [
        "We can inspect the architecture of our model by printing a summary as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22Fgvk9CshP4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4Hrrnrsqv3A"
      },
      "source": [
        "Additionally, before the model is fitted for training, it is necessary to configure the specifications as follows:\n",
        "\n",
        "*   **loss**: with a sigmoid activation function in the final step, we select `binary_crossentropy` as the loss function\n",
        "*   **optimizer**: `RMSprop` (Root Mean Square Propagation) with a learning rate of 0.001 will be used\n",
        "*   **metrics**: we will use `accuracy` as our metric to evaluate the prediction accuracy on every epoch\n",
        "\n",
        "We can now compile the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vIpy4YR2rZ0"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.001), metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8i-sVkIB2pym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### **_Your turn_: Exercises**"
      ],
      "metadata": {
        "id": "WhRg0cq656Oa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1**: Define a sequential model for our images that consists of only three convolutions. Also add one or two dropout layers. Store this as variable `model2`."
      ],
      "metadata": {
        "id": "TxyVGtx06FHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WivA8_f455hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFa3FDfS8zg8"
      },
      "source": [
        "---\n",
        "## **5. Model training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhrsxPiF7aiY"
      },
      "source": [
        "Now we are ready to train our model. We will train for 10 epochs with 10 steps (= batches of samples) on every epoch, and store our progress in `history`. Note that this might take a few minutes - time for some tea or coffee!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApgFjCYT7OG5"
      },
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 10,\n",
        "    epochs = 10,\n",
        "    validation_data = val_generator\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU1-aRZaAXnH"
      },
      "source": [
        "**Taking too long?** If you've finished your tea or coffee but the above is still not done, you can also interrupt execution of the cell by clicking on `Runtime > Interrupt execution` in the top menu. Now you can just download the result by un-commenting and executing the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJsN7lTzByCC"
      },
      "source": [
        "# !wget -O history.pickle https://www.dropbox.com/s/p34wvankor1ysiz/history.pickle?dl=0\n",
        "# file_to_read = open('history.pickle', 'rb')\n",
        "# history = pickle.load(file_to_read)\n",
        "# file_to_read.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHzSGLGeqU7_"
      },
      "source": [
        "---\n",
        "## **6. Model evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHiW6pFo_9We"
      },
      "source": [
        "To evaluate our model, we can plot the accuracy as a function of training epochs for our training and validation data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7H4BzqO_X_R"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTMc5JGOOutp"
      },
      "source": [
        "---\n",
        "#### **_Your turn_: Exercises**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_t86ELtOutr"
      },
      "source": [
        "**Exercise 1**: Plot the loss instead of the accuracy for training and validation data. Place the legend in the upper right corner of the plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krNRYiRwOuts"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9Kn0axUEAJI"
      },
      "source": [
        "---\n",
        "## **7. Model prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrM3Cu6OFsDf"
      },
      "source": [
        "So how does our model perform on unseen data? We can use the `model.evaluate` function to check this.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q8qexSGFrvl"
      },
      "source": [
        "result = model.evaluate(test_generator)\n",
        "print('loss for test data :', result[0])\n",
        "print('accuracy for test data :', result[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkwR7BI_Gl7n"
      },
      "source": [
        "You will probably receive a prediction accuracy upwards of 80%, which is not bad for such a simple model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTcKMmnPG2pk"
      },
      "source": [
        "Now our model is ready to make predictions! This can be done with the `model.predict` function. To predict whether a given image corresponds to a patient with or without pneumonia, we first need to download the image file and feed it into the `model.predict` function. For simplicity, we will use a file from the test data set, but we could of course also use our model for any other chest X-ray! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2_mvhL0D-1o"
      },
      "source": [
        "!wget -O test_image_1.jpeg https://www.dropbox.com/s/z2dwy069smbrtym/test_image_1.jpeg?dl=0\n",
        "path = 'test_image_1.jpeg'  # File path to an image from the test data set\n",
        "img = image.load_img(path, target_size=(300,300))   # Load image\n",
        "x = image.img_to_array(img)     # Turn image into array\n",
        "x = np.expand_dims(x, axis=0)   # Add one dimension to match the input size expected by our model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjoLy7T0Kx0G"
      },
      "source": [
        "classes = model.predict(x)\n",
        "prob_pneumonia = classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KooWY7lOknuH"
      },
      "source": [
        "---\n",
        "#### **_Your turn_: Exercises**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMh_LLQ6XJEz"
      },
      "source": [
        "**Exercise 1**: The variable `prob_pneumonia` gives the probability that the image comes from a pneumonia patient. Write a few lines of code to print 'The patient has pneumonia' if this probability is greater than 50%, and 'The patient does not have pneumonia' otherwise.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikg7piuDXQSg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ2baKahXaRR"
      },
      "source": [
        "**Exercise 2**: As (future) medical doctors, you might also want to take a look at the image yourself. You can display it using the `imshow` function of `matplotlib` as shown below. Do you agree with your model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMAQIBeGOPTk"
      },
      "source": [
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUpkAxjrU9ec"
      },
      "source": [
        "**Exercise 3**: If you're still feeling motivated, you can repeat the evaluation for the image file called `test_image_2.jpeg` which you can download from https://www.dropbox.com/s/z471e1sbeac29g7/test_image_2.jpeg?dl=0."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4:** If you're STILL feeling motivated and you have some time to spare this afternoon: What happens if, instead of our model with five convolutions, you use your model with only three convolutions (`model2`)? Does this affect the performance of your model?"
      ],
      "metadata": {
        "id": "xmsFrKYg6pqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **8. Optional: More MNIST**"
      ],
      "metadata": {
        "id": "YWqA8NKd7Ewp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you can try out how different network architectures and training parameters affect the performance of a deep learning model for the MNIST dataset. We will start with the following architecture:\n",
        "*   input shape 28×28×1 (the size of the images),\n",
        "*   1st hidden (convolutional) layer with 32 filters, kernel size (3,3), stride (1,1) and ReLu activations,\n",
        "    2nd hidden (convolutional) layer with 64 filters, kernel size (3,3), stride (1,1) and ReLu activations,\n",
        "    3rd hidden (convolutional) layer with 256 filters, kernel size (3,3), stride (1,1) and tanh activations,\n",
        "    output layer with 10 units and softmax activation.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qmee_y0G94m7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load and prepare data**"
      ],
      "metadata": {
        "id": "t1-MzujF-Qfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the MNIST dataset\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load MNIST images and labels and normalise (range 0 to 1) image data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data() # 60,000 training + 10,000 test images/labels\n",
        "X_train = X_train / 255.0\n",
        "X_test  = X_test / 255.0\n",
        "\n",
        "# Reshape dataset to have a single channel \n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)) # The CNN requires this layout (batch_size, height, width, n_channels)\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)) # The CNN requires this layout (batch_size, height, width, n_channels)\n",
        "\n",
        "# One-hot encode target values (i.e. make all the values 0 or 1)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "vFqxc8AD94aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build model**"
      ],
      "metadata": {
        "id": "OoIimFom-gWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(28,28,1)))\n",
        "model.add(Conv2D(64, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
        "model.add(Flatten()) # This flattens your image with width and height into a vector of length widht*height. \n",
        "model.add(Dense(10, activation='softmax')) \n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "eh0Jv9Hs7EK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compile model**"
      ],
      "metadata": {
        "id": "z02Qnhtg-rrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "# Loss function\n",
        "loss = CategoricalCrossentropy()\n",
        "\n",
        "model.compile(loss=loss,\n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "G4-KlOTd6km7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train model**"
      ],
      "metadata": {
        "id": "gTIQcz6N_g8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define number of epochs and batch size\n",
        "epochs = 5\n",
        "batch_size = 512\n",
        "\n",
        "# Fit model\n",
        "history = model.fit(x=X_train, y=y_train, \n",
        "                    validation_split=0.1,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size)"
      ],
      "metadata": {
        "id": "kn6fA1w2_CFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot loss and accuracy as a function of epochs**"
      ],
      "metadata": {
        "id": "hMvOdfh1-u0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = np.arange(0,epochs)\n",
        "\n",
        "fig, (ax1,ax2) = plt.subplots(2,1,figsize=(8,16))\n",
        "ax1.plot(n_epochs, history.history['loss'], label='training loss')\n",
        "ax1.plot(n_epochs, history.history['val_loss'], label='validation loss')\n",
        "ax1.set_ylim(-0.05,1.05)\n",
        "ax1.legend()\n",
        "\n",
        "ax2.plot(n_epochs, history.history['accuracy'], label='training accuracy')\n",
        "ax2.plot(n_epochs, history.history['val_accuracy'], label='validation accuracy')\n",
        "ax2.set_ylim(-0.05,1.05)\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ISmWKXVy_Kr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate model**"
      ],
      "metadata": {
        "id": "Bc5WsRka_nCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_and_metrics = model.evaluate(X_test, y_test, \n",
        "                                  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "W37EqAu7_moq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### **_Your turn_: Exercises**"
      ],
      "metadata": {
        "id": "cPwXxwv7AHhb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1:** Try changing the architecture of your model, e.g. by adding layers or changing the type of layers. How does this affect model performance?"
      ],
      "metadata": {
        "id": "XQC6E8gTAUWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 2:** Try changing the training parameters of your model, e.g. the number of epochs or the batch size. How does this affect model performance?"
      ],
      "metadata": {
        "id": "ssZH4DbyAoMt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxF7RTDcwRgR"
      },
      "source": [
        "#**Well done!**\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}